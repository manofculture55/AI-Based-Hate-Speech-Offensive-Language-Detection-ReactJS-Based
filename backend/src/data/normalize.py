import pandas as pd
import os
import sqlite3
import warnings

# --- IMPORT MODULAR FUNCTIONS ---
# This satisfies "Clean Modular Code" requirement [Section 8]
from backend.src.data.preprocess import clean_text
from backend.src.data.langid import detect_language_strict

warnings.filterwarnings("ignore")

# Define Paths
# --- PATH RESOLUTION (SAFE & ABSOLUTE) ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
BACKEND_DIR = os.path.abspath(os.path.join(BASE_DIR, "..", ".."))
DATA_DIR = os.path.join(BACKEND_DIR, "data")

DB_PATH = os.path.join(DATA_DIR, "app.db")
FINAL_CSV = os.path.join(DATA_DIR, "clean_data.csv")


def save_to_db(df):
    """Saves processed data to SQLite 'annotations' table [Section 4]."""
    conn = sqlite3.connect(DB_PATH)
    df.to_sql('annotations', conn, if_exists='replace', index=False) 
    conn.close()
    print("‚úÖ Data saved to SQLite 'annotations' table.")

# --- DATASET PROCESSORS ---

def process_hasoc_english():
    path = os.path.join(DATA_DIR, "hasoc2019_en_test-2919.tsv")
    if not os.path.exists(path): return None
    
    df = pd.read_csv(path, sep='\t', quoting=3)
    
    def get_label(row):
        t1, t2 = str(row.get('task_1','')), str(row.get('task_2',''))
        if t1 == 'NOT': return 0
        if t2 == 'HATE': return 2
        return 1 

    df['text'] = df['text'].apply(clean_text)
    df['truelabel'] = df.apply(get_label, axis=1)
    df['lang'] = df['text'].apply(lambda x: detect_language_strict(x, "english"))
    return df[['text', 'truelabel', 'lang']]

def process_hasoc_hindi(filename):
    path = os.path.join(DATA_DIR, filename)
    if not os.path.exists(path): return None
    
    try:
        df = pd.read_csv(path, sep='\t', quoting=3, on_bad_lines='skip')
    except:
        df = pd.read_csv(path, sep='\t', on_bad_lines='skip')

    def get_label(row):
        t1, t2 = str(row.get('task_1','')), str(row.get('task_2',''))
        if t1 == 'NOT': return 0
        if t2 == 'HATE': return 2
        return 1

    df['text'] = df['text'].apply(clean_text)
    df['truelabel'] = df.apply(get_label, axis=1)
    df['lang'] = df['text'].apply(lambda x: detect_language_strict(x, "hindi_mixed"))
    return df[['text', 'truelabel', 'lang']]

def process_mdpi():
    path = os.path.join(DATA_DIR, "MDPI2025_Dataset.csv")
    if not os.path.exists(path): return None
    
    df = pd.read_csv(path, encoding='utf-8')
    label_map = {0: 0, 1: 1, 2: 2, 3: 1}
    
    df['text'] = df['comment'].apply(clean_text)
    df['truelabel'] = df['label'].map(label_map).fillna(0).astype(int)
    df['lang'] = df['text'].apply(lambda x: detect_language_strict(x, "english"))
    return df[['text', 'truelabel', 'lang']]

def process_indo_hate():
    path = os.path.join(DATA_DIR, "prime_Indo_HateSpeech_Dataset.xlsx")
    if not os.path.exists(path): return None
    
    df = pd.read_excel(path)
    
    def map_indo_label(l):
        l = str(l).strip().replace("'", "")
        if 'HS0' in l: return 0
        if 'HS1' in l: return 1
        if 'HSN' in l or 'HS2' in l: return 2
        return 0

    df['text'] = df['Comment'].apply(clean_text)
    df['truelabel'] = df['Label'].apply(map_indo_label)
    df['lang'] = df['text'].apply(lambda x: detect_language_strict(x, "indo_mixed"))
    return df[['text', 'truelabel', 'lang']]

# --- MAIN EXECUTION ---

if __name__ == "__main__":
    print("üöÄ Starting Modular Data Normalization...")
    dfs = []
    
    # Add datasets if they exist
    d1 = process_hasoc_english()
    if d1 is not None: dfs.append(d1)
    
    d2 = process_hasoc_hindi("hasoc2019_hi_test_gold_2919.tsv")
    if d2 is not None: dfs.append(d2)
    
    d3 = process_hasoc_hindi("hindi_dataset.csv")
    if d3 is not None: dfs.append(d3)
    
    d4 = process_mdpi()
    if d4 is not None: dfs.append(d4)
    
    d5 = process_indo_hate()
    if d5 is not None: dfs.append(d5)
    
    if dfs:
        final_df = pd.concat(dfs, ignore_index=True)
        final_df.drop_duplicates(subset=['text'], inplace=True)
        final_df = final_df[final_df['text'].str.len() > 2]
        
        final_df.to_csv(FINAL_CSV, index=False)
        save_to_db(final_df)
        
        print(final_df.columns)
        print(f"\n‚úÖ SUCCESS! Processed {len(final_df)} rows.")
        print(final_df['lang'].value_counts())
    else:
        print("‚ùå No data processed.")